{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acac16af-bebb-47d0-9328-0bca3864da7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp310-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch) (4.13.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.0-cp310-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 mpmath-1.3.0 sympy-1.14.0 torch-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da447c7b-373e-4f05-b19b-5ab50413f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: torch==2.7.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch==2.7.0->torchvision) (4.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/tf_py310/lib/python3.10/site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.22.0-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9137e8d-c96b-448a-a0ff-cda33eaa577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8d2e758-0ab5-4460-b277-7402d2a96e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_HR_DIR   = \"/Users/snehabejugam/Downloads/div2k/DIV2K_train_HR/DIV2K_train_HR\"\n",
    "VAL_HR_DIR     = \"/Users/snehabejugam/Downloads/div2k/DIV2K_valid_HR/DIV2K_valid_HR\"\n",
    "SCALE_FACTOR   = 2\n",
    "HR_PATCH_SIZE  = 256\n",
    "BATCH_SIZE     = 16\n",
    "NUM_EPOCHS     = 10\n",
    "LEARNING_RATE  = 1e-4\n",
    "BETA1, BETA2   = 0.9, 0.999\n",
    "NUM_WORKERS    = 0   \n",
    "PIN_MEMORY     = False  \n",
    "LAMBDA_CONTENT = 1.0\n",
    "LAMBDA_ADV     = 0.001\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "720d4c75-779c-428c-9f8f-17ed7dd53950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIV2KDataset_HR_Only(Dataset):\n",
    "    def __init__(self, hr_dir, scale=4, patch_size=96, use_random_crop=True):\n",
    "        super().__init__()\n",
    "        self.hr_files = sorted(glob.glob(os.path.join(hr_dir, '*.png')))\n",
    "        if not self.hr_files:\n",
    "            raise FileNotFoundError(f\"No PNG images found in {hr_dir}\")\n",
    "        if patch_size % scale != 0:\n",
    "            raise ValueError(\"patch_size must be divisible by scale\")\n",
    "        self.scale = scale\n",
    "        self.patch_size = patch_size\n",
    "        self.lr_patch = patch_size // scale\n",
    "        self.random_crop = use_random_crop\n",
    "        print(f\"Loaded {len(self.hr_files)} HR images from {hr_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.hr_files[idx]\n",
    "        try:\n",
    "            hr = Image.open(path).convert('RGB')\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        w, h = hr.size\n",
    "        if self.random_crop:\n",
    "            if w < self.patch_size or h < self.patch_size:\n",
    "                hr_patch = TF.resize(hr, (self.patch_size, self.patch_size),\n",
    "                                     interpolation=InterpolationMode.BICUBIC)\n",
    "            else:\n",
    "                i = random.randint(0, h - self.patch_size)\n",
    "                j = random.randint(0, w - self.patch_size)\n",
    "                hr_patch = TF.crop(hr, i, j, self.patch_size, self.patch_size)\n",
    "        else:\n",
    "            if w < self.patch_size or h < self.patch_size:\n",
    "                hr_patch = TF.resize(hr, (self.patch_size, self.patch_size),\n",
    "                                     interpolation=InterpolationMode.BICUBIC)\n",
    "            else:\n",
    "                hr_patch = TF.center_crop(hr, (self.patch_size, self.patch_size))\n",
    "\n",
    "        # --- Generate LR patch ---\n",
    "        lr_patch = TF.resize(hr_patch,\n",
    "                             (self.lr_patch, self.lr_patch),\n",
    "                             interpolation=InterpolationMode.BICUBIC)\n",
    "\n",
    "        # --- To tensor & normalize to [-1,1] ---\n",
    "        hr_t = TF.to_tensor(hr_patch)\n",
    "        lr_t = TF.to_tensor(lr_patch)\n",
    "        hr_t = TF.normalize(hr_t, [0.5]*3, [0.5]*3)\n",
    "        lr_t = TF.normalize(lr_t, [0.5]*3, [0.5]*3)\n",
    "        return lr_t, hr_t\n",
    "\n",
    "\n",
    "def custom_collate(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return None if not batch else torch.utils.data.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e808fcc-42ca-48d8-8d07-332174062eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c, c, 3, padding=1), nn.BatchNorm2d(c), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c, c, 3, padding=1), nn.BatchNorm2d(c)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.net(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, scale=4, n_res=5, c=64):\n",
    "        super().__init__()\n",
    "        self.conv_in  = nn.Conv2d(3, c, 9, padding=4)\n",
    "        self.relu     = nn.ReLU(inplace=True)\n",
    "        self.res_blocks = nn.Sequential(*(ResidualBlock(c) for _ in range(n_res)))\n",
    "        self.conv_mid = nn.Conv2d(c, c, 3, padding=1)\n",
    "        up = []\n",
    "        for _ in range(int(np.log2(scale))):\n",
    "            up += [nn.Conv2d(c, c*4, 3, padding=1),\n",
    "                   nn.PixelShuffle(2),\n",
    "                   nn.ReLU(inplace=True)]\n",
    "        self.up       = nn.Sequential(*up)\n",
    "        self.conv_out = nn.Conv2d(c, 3, 9, padding=4)\n",
    "        self.tanh     = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.conv_in(x))\n",
    "        x2 = self.res_blocks(x1)\n",
    "        x3 = self.conv_mid(x2) + x1\n",
    "        x4 = self.up(x3)\n",
    "        return self.tanh(self.conv_out(x4))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def block(in_c, out_c, bn=True):\n",
    "            layers = [nn.Conv2d(in_c, out_c, 4, 2, 1, bias=not bn)]\n",
    "            if bn: layers.append(nn.BatchNorm2d(out_c))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        self.net = nn.Sequential(\n",
    "            *block(3, 64, bn=False),\n",
    "            *block(64,128),\n",
    "            *block(128,256),\n",
    "            *block(256,512),\n",
    "            nn.Conv2d(512,1,4,1,1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ad2e87c-9022-4963-b986-8b4a66ddd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gen, loader, device):\n",
    "    gen.eval()\n",
    "    tot_psnr = tot_ssim = n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if batch is None: continue\n",
    "            lr, hr = batch\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            sr = gen(lr)\n",
    "\n",
    "            # take first image\n",
    "            sr_img = ((sr[0].permute(1,2,0).cpu().clamp(-1,1)+1)/2).numpy()\n",
    "            hr_img = ((hr[0].permute(1,2,0).cpu().clamp(-1,1)+1)/2).numpy()\n",
    "\n",
    "            psnr = compare_psnr(hr_img, sr_img, data_range=1)\n",
    "            ssim = compare_ssim(hr_img, sr_img, data_range=1, channel_axis=-1, win_size=7)\n",
    "            tot_psnr += psnr\n",
    "            tot_ssim += ssim\n",
    "            n += 1\n",
    "    gen.train()\n",
    "    return (tot_psnr/n, tot_ssim/n) if n else (0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46108544-affc-4ee8-b8a0-2076158d570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 800 HR images from /Users/snehabejugam/Downloads/div2k/DIV2K_train_HR/DIV2K_train_HR\n",
      "Loaded 100 HR images from /Users/snehabejugam/Downloads/div2k/DIV2K_valid_HR/DIV2K_valid_HR\n",
      "Train batches: 50, Val batches: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████| 50/50 [13:58<00:00, 16.78s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | D_loss: 0.5937 | G_loss: 0.2129\n",
      " → Val PSNR: 20.2583 dB | SSIM: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████| 50/50 [13:58<00:00, 16.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | D_loss: 0.2037 | G_loss: 0.1397\n",
      " → Val PSNR: 22.2671 dB | SSIM: 0.5668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████| 50/50 [14:00<00:00, 16.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | D_loss: 0.0914 | G_loss: 0.1227\n",
      " → Val PSNR: 22.6553 dB | SSIM: 0.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████| 50/50 [14:07<00:00, 16.94s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | D_loss: 0.1033 | G_loss: 0.1129\n",
      " → Val PSNR: 23.3021 dB | SSIM: 0.6449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████| 50/50 [14:05<00:00, 16.92s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | D_loss: 0.1177 | G_loss: 0.1028\n",
      " → Val PSNR: 23.6722 dB | SSIM: 0.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████| 50/50 [31:15<00:00, 37.51s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | D_loss: 0.0988 | G_loss: 0.0984\n",
      " → Val PSNR: 24.1227 dB | SSIM: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████| 50/50 [16:05<00:00, 19.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | D_loss: 0.1374 | G_loss: 0.0928\n",
      " → Val PSNR: 24.7016 dB | SSIM: 0.7153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████| 50/50 [52:56<00:00, 63.54s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | D_loss: 0.1034 | G_loss: 0.0907\n",
      " → Val PSNR: 24.8592 dB | SSIM: 0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████| 50/50 [18:43<00:00, 22.48s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | D_loss: 0.2006 | G_loss: 0.0852\n",
      " → Val PSNR: 25.0509 dB | SSIM: 0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|███████████████████████████| 50/50 [18:20<00:00, 22.00s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | D_loss: 0.2527 | G_loss: 0.0812\n",
      " → Val PSNR: 25.6096 dB | SSIM: 0.7583\n",
      "\n",
      "Training complete in 212.9 min\n",
      "Average PSNR over 10 epochs : 23.6499 dB\n",
      "Average SSIM over 10 epochs: 0.6600\n",
      "Highest PSNR was 25.6096 dB at epoch 10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for d in (TRAIN_HR_DIR, VAL_HR_DIR):\n",
    "        if not os.path.isdir(d):\n",
    "            print(f\"ERROR: directory not found: {d}\")\n",
    "            exit(1)\n",
    "\n",
    "    train_ds = DIV2KDataset_HR_Only(\n",
    "        TRAIN_HR_DIR, scale=SCALE_FACTOR,\n",
    "        patch_size=HR_PATCH_SIZE, use_random_crop=True\n",
    "    )\n",
    "    val_ds = DIV2KDataset_HR_Only(\n",
    "        VAL_HR_DIR, scale=SCALE_FACTOR,\n",
    "        patch_size=HR_PATCH_SIZE, use_random_crop=False\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "        collate_fn=custom_collate\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=1, shuffle=False,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "        collate_fn=custom_collate\n",
    "    )\n",
    "\n",
    "    print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
    "\n",
    "    G = Generator(scale=SCALE_FACTOR).to(device)\n",
    "    D = Discriminator().to(device)\n",
    "\n",
    "    content_loss = nn.L1Loss().to(device)\n",
    "    adv_loss     = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    opt_g = optim.Adam(G.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
    "    opt_d = optim.Adam(D.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
    "\n",
    "    best_psnr    = 0.0\n",
    "    best_epoch   = 0\n",
    "    psnr_history = []\n",
    "    ssim_history = []\n",
    "    t0           = time.time()\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        G.train(); D.train()\n",
    "        running_g = running_d = 0.0\n",
    "\n",
    "        loop = train_loader\n",
    "        if VERBOSE:\n",
    "            loop = tqdm(train_loader,\n",
    "                        desc=f\"Epoch {epoch}/{NUM_EPOCHS}\",\n",
    "                        unit=\"batch\")\n",
    "\n",
    "        for batch in loop:\n",
    "            if batch is None: \n",
    "                continue\n",
    "            lr_b, hr_b = batch\n",
    "            lr_b, hr_b = lr_b.to(device), hr_b.to(device)\n",
    "\n",
    "           \n",
    "            with torch.no_grad():\n",
    "                out_shape = D(hr_b).shape\n",
    "            real_lbl = torch.ones(out_shape, device=device)\n",
    "            fake_lbl = torch.zeros(out_shape, device=device)\n",
    "\n",
    "           \n",
    "            opt_d.zero_grad()\n",
    "            real_out  = D(hr_b)\n",
    "            fake_img  = G(lr_b).detach()\n",
    "            fake_out  = D(fake_img)\n",
    "            loss_d    = 0.5 * (adv_loss(real_out, real_lbl) +\n",
    "                              adv_loss(fake_out, fake_lbl))\n",
    "            loss_d.backward(); opt_d.step()\n",
    "\n",
    "       \n",
    "            opt_g.zero_grad()\n",
    "            gen_img = G(lr_b)\n",
    "            loss_g  = (LAMBDA_CONTENT * content_loss(gen_img, hr_b) +\n",
    "                       LAMBDA_ADV * adv_loss(D(gen_img), real_lbl))\n",
    "            loss_g.backward(); opt_g.step()\n",
    "\n",
    "            running_d += loss_d.item()\n",
    "            running_g += loss_g.item()\n",
    "\n",
    "        avg_d = running_d / len(train_loader)\n",
    "        avg_g = running_g / len(train_loader)\n",
    "        print(f\"Epoch {epoch}/{NUM_EPOCHS} | D_loss: {avg_d:.4f} | G_loss: {avg_g:.4f}\")\n",
    "\n",
    "       \n",
    "        psnr_val, ssim_val = evaluate(G, val_loader, device)\n",
    "        print(f\" → Val PSNR: {psnr_val:.4f} dB | SSIM: {ssim_val:.4f}\")\n",
    "\n",
    "        psnr_history.append(psnr_val)\n",
    "        ssim_history.append(ssim_val)\n",
    "\n",
    "        if psnr_val > best_psnr:\n",
    "            best_psnr  = psnr_val\n",
    "            best_epoch = epoch\n",
    "            torch.save(G.state_dict(), \"generator_best.pth\")\n",
    "            torch.save(D.state_dict(), \"discriminator_best.pth\")\n",
    "\n",
    "  \n",
    "    total_min  = (time.time() - t0) / 60\n",
    "    avg_psnr   = sum(psnr_history) / len(psnr_history)\n",
    "    avg_ssim   = sum(ssim_history) / len(ssim_history)\n",
    "\n",
    "    print(f\"\\nTraining complete in {total_min:.1f} min\")\n",
    "    print(f\"Average PSNR over {len(psnr_history)} epochs : {avg_psnr:.4f} dB\")\n",
    "    print(f\"Average SSIM over {len(ssim_history)} epochs: {avg_ssim:.4f}\")\n",
    "    print(f\"Highest PSNR was {best_psnr:.4f} dB at epoch {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c20048-6dad-4f88-aced-b366ebee11a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf)",
   "language": "python",
   "name": "tf_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
